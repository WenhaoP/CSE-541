{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 541 Homework 1\n",
    "Evan Komp\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "Prove Markov's inequality eg $P(X > \\lambda)\\le \\mathbb{E}(X)/\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition of the expected value, for a positive random variable $X$:\n",
    "\n",
    "$$\\mathbb{E}(X) = \\int_0^\\inf xf(x)dx$$\n",
    "\n",
    "Due to the law of total probability, $f(x)\\ge 0$:\n",
    "\n",
    "$$\\ge \\int_\\lambda^\\inf xf(x)dx$$\n",
    "\n",
    "Given that $X$ is real, positive, and greater than lambda:\n",
    "\n",
    "$$\\ge \\lambda\\int_\\lambda^\\inf f(x)dx$$\n",
    "\n",
    "By definition of the cummaltive distributio. function\n",
    "> $$\\ge \\lambda P(X>\\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a random vector $X\\in \\mathbb{R}^d$ with convex function $\\phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}$. Show for discrete $X$ that $\\phi(\\mathbb{E}(X)) \\le \\mathbb{E}(\\phi(X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the definition of convexity for $x_i\\in X$: $\\phi(tx_i+(1-t)x_j)\\le t\\phi(x_i)+(1-t)\\phi(x_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our expected value $\\mathbb{E}(X)=\\Sigma_i^n x_i p(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the law of total probability:\n",
    "$$\\phi(\\Sigma_{i=1}^nx_ip(x_i)) = \\phi(x_1p(x_1)+(1-p(x_1))\\frac{\\Sigma_{i=2}^nx_ip(x_i)}{\\Sigma_{i=2}^np(x_i)})$$\n",
    "\n",
    "Given that the function is convex:\n",
    "\n",
    "$$\\le p(x_1)\\phi(x_1)+(1-p(x_1))\\phi(\\frac{\\Sigma_{i=2}^nx_ip(x_i)}{\\Sigma_{i=2}^np(x_i)})$$\n",
    "\n",
    "Given that the function maps a vector of length d to a scalar, we have the scalar denominator as independant:\n",
    "$$\\le x_1p(x_1)+\\frac{1-p(x_1)}{\\Sigma_{i=2}^np(x_i)}\\Sigma_{i=2}^nx_ip(x_i) = x_1p(x_1)+\\Sigma_{i=2}^nx_ip(x_i)$$\n",
    "\n",
    "Repeating n times yields:\n",
    "\n",
    ">$$\\phi(\\mathbb{E}(X))\\le \\phi(x_1)p(x_1)+,...,+x_np(x_n) = \\mathbb{E}(\\phi(X))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "If $X_i$ are independant random sub gaussian variables with $\\mathbb{E}[\\exp(\\lambda(X_i - \\mathbb{E}(X_i)))]\\le \\exp(\\lambda^2\\sigma^2/2)$ for $\\lambda \\gt 0$, and $Z=\\Sigma X_i$\n",
    "\n",
    "By identity:\n",
    "$$\\mathbb{E}[\\exp(\\lambda(Z-a))] = \\mathbb{E}[\\Pi_i\\exp(\\lambda X_i)\\exp(-\\lambda a)]=\\exp(\\lambda(\\Sigma_i\\mathbb{E}(X_i)-a))\\mathbb{E}[\\Pi_i\\exp(\\lambda( X_i-\\mathbb{E}(X_i)))]$$\n",
    "\n",
    "By independant random variables:\n",
    "$$=\\exp(\\lambda(\\Sigma_i\\mathbb{E}(X_i)-a))\\Pi_i\\mathbb{E}[\\exp(\\lambda( X_i-\\mathbb{E}(X_i)))]$$\n",
    "\n",
    "By each being sub gaussian:\n",
    "$$\\le \\exp(\\lambda(\\Sigma_i\\mathbb{E}(X_i)-a))\\Pi_i \\exp(\\lambda^2\\sigma_i^2/2)$$\n",
    "\n",
    "So our target bound becomes: \n",
    "$$\\exp(\\lambda(\\Sigma_i\\mathbb{E}(X_i)-a))\\Pi_i \\exp(\\lambda^2\\sigma_i^2/2)\\le \\exp(\\lambda^2b/2)$$\n",
    "\n",
    "Taking the log and simplifying:\n",
    "$$\\lambda\\frac{b-\\Sigma\\sigma_i^2}{2} - \\Sigma\\mathbb{E}(X_i)+a \\le 0$$\n",
    "\n",
    "This must be true for all $\\lambda > 0$, thus taking $\\lim_{\\lambda\\rightarrow 0}$ yields:\n",
    "\n",
    "$$a \\le \\Sigma\\mathbb{E}(X_i)$$\n",
    "$$b \\ge\\frac{\\Sigma\\mathbb{E}(X_i)-a}{\\lambda}2+\\Sigma\\sigma_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "If $X_i$ with $i=1,...,n$ be a sub gaussian random variable with $\\mathbb{E}(\\exp(\\lambda X_i))\\le \\exp(\\sigma_i^2\\lambda^2/2)$ what is the upper bound on $\\mathbb{E}(\\max_iX_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the identity given as a hint:\n",
    "$$\\mathbb{E}(\\max_iX_i)=\\frac{1}{\\lambda}\\ln(\\exp(\\lambda\\mathbb{E}[\\max_iX_i]))$$\n",
    "\n",
    "And by Jensen's inequality on the exponentiation function:\n",
    "$$\\le \\frac{1}{\\lambda}\\ln(\\mathbb{E}[\\exp(\\lambda\\max_iX_i)])$$\n",
    "\n",
    "The max cannot be more than the sum:\n",
    "$$\\le \\frac{1}{\\lambda}\\ln(\\mathbb{E}[\\exp(\\lambda\\Sigma_iX_i)]) = \\frac{1}{\\lambda}\\ln(\\mathbb{E}[\\Pi_i\\exp(\\lambda X_i)])$$\n",
    "\n",
    "Independance:\n",
    "$$= \\frac{1}{\\lambda}\\ln(\\Pi_i\\mathbb{E}[\\exp(\\lambda X_i)])$$\n",
    "\n",
    "Sub Gaussian:\n",
    "$$\\le \\frac{1}{\\lambda}\\ln(\\Pi_i\\exp(\\sigma_i^2\\lambda^2/2))$$\n",
    "\n",
    "A product of n numbers is at most the product of the maximum number n times:\n",
    "$$\\le \\frac{1}{\\lambda}\\ln(n\\exp(\\max_i\\sigma_i^2\\lambda^2/2))$$\n",
    "$$=\\frac{\\ln(n)}{\\lambda}+\\max_i\\sigma_i^2\\lambda/2$$\n",
    "\n",
    "Minimize w.r.t $\\lambda$:\n",
    "$$\\lambda \\ge \\sqrt{\\frac{\\ln(n)2}{\\max_i\\sigma_i^2}}$$\n",
    "\n",
    "Thus:\n",
    "$$\\mathbb{E}(max_iX_i) \\le \\sqrt{2\\max_i\\sigma_i^2\\ln(n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Upper Confidence Bound Algortithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4 - implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB:\n",
    "    \n",
    "    def __init__(self, T: int, arms: List[object]):\n",
    "        self.T = T\n",
    "        self.arms = arms\n",
    "        self.n = len(arms)\n",
    "        self.history = []\n",
    "        self.observations = []\n",
    "        self.ucbs = []\n",
    "        self.emp_means = []\n",
    "        return\n",
    "    \n",
    "    def pull(self, arm_num):\n",
    "        self.history.append(arm_num)\n",
    "        self.observations.append(self.arms[arm_num].rvs())\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def means(self):\n",
    "        return np.array([arm.mean() for arm in self.arms])\n",
    "    \n",
    "    @property\n",
    "    def delts(self):\n",
    "        best = max(self.means)\n",
    "        return best - self.means\n",
    "    \n",
    "    def get_Ti_s(self, time=None):\n",
    "        if time == None:\n",
    "            history = np.array(self.history)\n",
    "        else:\n",
    "            time += 1\n",
    "            history = np.array(self.history)[:time]\n",
    "        _, counts = np.unique(history, return_counts=True)\n",
    "        return counts\n",
    "    \n",
    "    def emp_mean(self, arm_num, time=None):\n",
    "        if time == None:\n",
    "            history = np.array(self.history)\n",
    "            observations = np.array(self.observations)\n",
    "        else:\n",
    "            time += 1\n",
    "            history = np.array(self.history)[:time]\n",
    "            observations = np.array(self.observations)[:time]\n",
    "        this_arm = history == arm_num\n",
    "        return np.mean(observations[this_arm])\n",
    "    \n",
    "    def startup(self):\n",
    "        for i in range(self.n):\n",
    "            self.pull(i)\n",
    "        return\n",
    "    \n",
    "    def get_emp_means(self, time=None):\n",
    "        return [self.emp_mean(i, time) for i in range(self.n)]\n",
    "    \n",
    "    def get_ucbs(self, time=None):\n",
    "        emp_means = self.get_emp_means(time)\n",
    "        Ti_s = self.get_Ti_s(time)\n",
    "        cbs = np.sqrt(2*np.log(2*self.n*self.T**2)/Ti_s)\n",
    "        ucbs = emp_means + cbs\n",
    "        return ucbs\n",
    "    \n",
    "    def step(self):\n",
    "        ucbs = self.get_ucbs()\n",
    "        It = np.argmax(ucbs)\n",
    "        self.pull(It)\n",
    "        return\n",
    "    \n",
    "    def run(self):\n",
    "        for t in range(self.T-len(self.observations)):\n",
    "            self.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = [.1]\n",
    "for i in range(9):\n",
    "    mus.append(0)\n",
    "mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "arms = [scipy.stats.norm(loc=mu) for mu in mus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb = UCB(2000, arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb.startup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02444899251450637,\n",
       " 0.007140185785129631,\n",
       " 0.004887495262721997,\n",
       " 0.05460667010696846,\n",
       " 0.0005995689457183507,\n",
       " 0.09060837863736011,\n",
       " 0.003155535572612362,\n",
       " 0.07189287159919107,\n",
       " -0.16665442758410742,\n",
       " 0.0065668775044989995]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucb.get_emp_means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43961509, 0.44252241, 0.44487706, 0.46414206, 0.44176401,\n",
       "       0.44125968, 0.43740836, 0.44389329, 0.43966811, 0.43748352])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucb.get_ucbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
